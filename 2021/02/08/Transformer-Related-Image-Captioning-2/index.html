<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.jpg?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/avatar.jpg?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/avatar.jpg?v=7.3.0">
  <link rel="mask-icon" href="/images/avatar.jpg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css">
  <script src="//cdn.jsdelivr.net/npm/pace-js@1/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":true,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="一、Normalized and Geometry-Aware Self-Attention Network for Image Captioning, CVPR2020  自制PPT   1、解决问题 随着Transformer在NLP领域的流行，它的self-attention（SA）的思想也逐渐被引入到image captioning领域。但是原始的SA有两个问题： 1）Internal">
<meta name="keywords" content="Image Caption,Attention Mechanism,Transformer">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformer-Related Image Captioning (2)">
<meta property="og:url" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/index.html">
<meta property="og:site_name" content="Ezeli&#39;s Blog">
<meta property="og:description" content="一、Normalized and Geometry-Aware Self-Attention Network for Image Captioning, CVPR2020  自制PPT   1、解决问题 随着Transformer在NLP领域的流行，它的self-attention（SA）的思想也逐渐被引入到image captioning领域。但是原始的SA有两个问题： 1）Internal">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/0f7e92dc5f2d7971e8af188c70c3fe3b.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/48863e047daf79c163d92c78639f64cd.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/7001d6d0202d2c415f8f2eef004707b5.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/5408aab9617d4eda383296ab1c8143bf.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/d885304eb20aa1098ecf62d92079a2e7.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/372424cc1f1e79b3a0308875b1ae2bad.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/f8917b4834f7a3f55dffc27f56a2d1cf.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/88e487fab24f864de16afbd765100079.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/cce28570ecb91db200372887723f3b5b.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/94cabd8ff45ccf81698498ec83a950ee.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/e22e8d5c883bfef5c2f8b9401cc15a38.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/87ba6a9bec047a5313fbdea67fd17ba8.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/1f726498ee2654388e56706d7a444e65.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/ef1e77cb36ae33b1b8f74fe8ea6c37ab.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/9044fde7e7b4fc15877f955a7d4cc816.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/8b89eac48a8db626a3ffd58a336c2f20.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/8b6a46a06722d0f46e2f4f8f4955e7a7.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/f60d0f9a2b66b297c80177a1a8f2e69e.png">
<meta property="og:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/786c6639e19249a1963e606fcc4d355f.png">
<meta property="og:updated_time" content="2021-02-08T11:09:53.928Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Transformer-Related Image Captioning (2)">
<meta name="twitter:description" content="一、Normalized and Geometry-Aware Self-Attention Network for Image Captioning, CVPR2020  自制PPT   1、解决问题 随着Transformer在NLP领域的流行，它的self-attention（SA）的思想也逐渐被引入到image captioning领域。但是原始的SA有两个问题： 1）Internal">
<meta name="twitter:image" content="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/0f7e92dc5f2d7971e8af188c70c3fe3b.png">
  <link rel="alternate" href="/atom.xml" title="Ezeli's Blog" type="application/atom+xml">
  <link rel="canonical" href="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Transformer-Related Image Captioning (2) | Ezeli's Blog</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ezeli's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">人生在勤，不索何获？</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
      </li>
    
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-wrapper">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content page-post-detail">
            

  <div id="posts" class="posts-expand">
    

  <article class="post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ezeli.github.io/2021/02/08/Transformer-Related-Image-Captioning-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ezeli">
      <meta itemprop="description" content="个人笔记：用于总结和回顾！">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ezeli's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Transformer-Related Image Captioning (2)

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2021-02-08 18:50:43 / 修改时间：19:09:53" itemprop="dateCreated datePublished" datetime="2021-02-08T18:50:43+08:00">2021-02-08</time>
            </span>
          
            

            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/论文阅读/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="一-normalized-and-geometry-aware-self-attention-network-for-image-captioning-cvpr2020"><a class="markdownIt-Anchor" href="#一-normalized-and-geometry-aware-self-attention-network-for-image-captioning-cvpr2020"></a> 一、Normalized and Geometry-Aware Self-Attention Network for Image Captioning, CVPR2020</h2>
<blockquote>
<p><a href="https://github.com/ezeli/notes_in_BIT/raw/master/PPT/CVPR2020%20Normalized%20and%20Geometry-Aware%20Self-Attention%20Network%20for%20Image%20Captioning.pptx" target="_blank" rel="noopener">自制PPT</a></p>
</blockquote>
<h3 id="1-解决问题"><a class="markdownIt-Anchor" href="#1-解决问题"></a> 1、解决问题</h3>
<p>随着Transformer在NLP领域的流行，它的self-attention（SA）的思想也逐渐被引入到image captioning领域。但是原始的SA有两个问题：</p>
<p>1）Internal Covariate Shift（ICS）问题：在训练过程中，由于网络参数的变化，当query的分布发生变化时，该层的输出的分布会发生变化，也就是说，随后的层必须不断适应新的输入分布，因此，SA可能无法有效地学习。</p>
<a id="more"></a>
<p>2）无法建模输入元素之间的几何关系，但是图片中的物体之间是有几何关系的，并且这种内在的关系有利于对视觉信息进行推理，对理解图片内容有很大帮助。在NLP中，对于1维的句子来说，SA将元素在序列中的绝对位置的表示添加到输入的每个元素中来建模位置关系，但是这对于image captioning是不适用的，因为2维的几何关系很难通过绝对位置来推断。</p>
<p>为此，作者提出Normalized Self-Attention (NSA)和Geometry-aware Self-Attention (GSA)分别解决以上两个问题，并把它们组合起来构建NG-SAN代替self-attention网络的编码器中的原始的SA模块。</p>
<h3 id="2-准备工作"><a class="markdownIt-Anchor" href="#2-准备工作"></a> 2、准备工作</h3>
<p>Self-Attention流程：首先将输入X映射为query（Q）、key（K）和value（V），之后通过Q和K得到权重E，最后通过E对V进行加权求和得到上下文向量Z：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/0f7e92dc5f2d7971e8af188c70c3fe3b.png" alt></p>
<p>之后，作者介绍了Self-Attention Network（SAN），并作为这篇论文的基准结构，如下图所示：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/48863e047daf79c163d92c78639f64cd.png" alt></p>
<p>由于图像中的区域没有像序列一样的自然顺序，因此在编码器中没有添加位置信息。</p>
<h3 id="3-模型"><a class="markdownIt-Anchor" href="#3-模型"></a> 3、模型</h3>
<h4 id="1normalized-sa-nsa"><a class="markdownIt-Anchor" href="#1normalized-sa-nsa"></a> 1）Normalized SA (NSA)：</h4>
<p>NSA为self-attention引入再参数化（reparameterization），利用标准化方法来改进模型训练。</p>
<p>再次回顾self-attention中注意力权重的计算：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/7001d6d0202d2c415f8f2eef004707b5.png" alt></p>
<p>可以认为将X经过两次线性映射，然后在通过一个softmax层，因此上式可以重写为：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/5408aab9617d4eda383296ab1c8143bf.png" alt></p>
<p>其中参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Θ</span></span></span></span>是基于X动态计算。从这个角度，SA会受到ICS问题的影响，也就是当输入Q的分布由于训练过程中网络参数的变化而发生变化时，下一层的参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Θ</span></span></span></span>需要不断适应新的输入分布，因此，SA可能无法有效地学习。所以，解决ICS问题，有利于Q的分布随时间推移而保持固定，这样<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Θ</span></span></span></span>就不需要为弥补Q分布的变化而进行调整。这可以通过在Q上执行标准化来实现。</p>
<p>此时，对Q执行批标准化（Batch Normalization）并不适用，因为参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Θ</span></span></span></span>并不是对于所有数据共享的，而是基于输入X动态计算得到的，因此，更可取的做法是对每个单独的实例执行标准化：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/d885304eb20aa1098ecf62d92079a2e7.png" alt></p>
<p>其中b表示一个批次中那个实例，t表示一个实例的那个区域特征，c表示一个区域特征的那个通道。将上述过程表示为实例标准化（Instance Normalization，IN），最后self-attention的再参数化表示为：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/372424cc1f1e79b3a0308875b1ae2bad.png" alt></p>
<p>注意：IN和LN（层标准化，Layer Normalization）是不一样的，LN对每个元素的所有通道进行标准化，而IN对每个实例的所有输入元素的每个通道进行标准化。</p>
<h4 id="2geometry-aware-sa-gsa"><a class="markdownIt-Anchor" href="#2geometry-aware-sa-gsa"></a> 2）Geometry-Aware SA (GSA)：</h4>
<p>将两个对象i和j之间的相对几何特征表示为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>f</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mi>g</mi></msubsup></mrow><annotation encoding="application/x-tex">f_{i,j}^{g}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1952720000000001em;vertical-align:-0.412972em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7823em;"><span style="top:-2.4231360000000004em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span></span></span></span>，这是包围盒相对位置和大小的四维向量：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/f8917b4834f7a3f55dffc27f56a2d1cf.png" alt></p>
<p>N个物体两两之间都包含一个相对几何特征，因此f的维度为N*N*4。之后，对原始SA中的注意力权重计算过程进行重写：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/88e487fab24f864de16afbd765100079.png" alt></p>
<p>φ是几何注意力函数，输出一个N*N的分数矩阵。Q’、K’是和G相同维度的query和key，和Q、K的计算方式相同。上式的第一项表示基于内容的权重，第二项表示几何偏差。下面介绍φ的三种选择，它们可以单独使用也可以组合使用：</p>
<p>内容无关的几何偏差：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/cce28570ecb91db200372887723f3b5b.png" alt></p>
<p>查询相关的几何偏差：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/94cabd8ff45ccf81698498ec83a950ee.png" alt></p>
<p>键相关的几何偏差：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/e22e8d5c883bfef5c2f8b9401cc15a38.png" alt></p>
<h4 id="3ng-san"><a class="markdownIt-Anchor" href="#3ng-san"></a> 3）NG-SAN</h4>
<p>首先将GSA中的Q通过NSA中的方法进行标准化，然后使用这个模块代替编码器中原始的SA模块，这样就构成了NG-SAN模型。</p>
<h2 id="二-meshed-memory-transformer-for-image-captioning-cvpr2020"><a class="markdownIt-Anchor" href="#二-meshed-memory-transformer-for-image-captioning-cvpr2020"></a> 二、Meshed-Memory Transformer for Image Captioning, CVPR2020</h2>
<blockquote>
<p><a href="https://github.com/ezeli/notes_in_BIT/raw/master/PPT/CVPR2020%20Meshed-Memory%20Transformer%20for%20Image%20Captioning.pptx" target="_blank" rel="noopener">自制PPT</a></p>
</blockquote>
<p>作者主要就是将Transformer中的注意力机制加入到Image Captioning模型中，概览图为：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/87ba6a9bec047a5313fbdea67fd17ba8.png" alt></p>
<p>主要创新：封装了图像区域的多层编码器和生成输出句子的多层解码器，并且为了利用低层次和高层次的图像区域之间的关系，编码层和解码层以网状结构连接，通过可学习的门控机制进行加权。</p>
<h4 id="1-meshed-memory-transformer"><a class="markdownIt-Anchor" href="#1-meshed-memory-transformer"></a> 1、Meshed-Memory Transformer</h4>
<p>分为编码器模块和解码器模块，它们都是注意力层的堆积。编码器负责找出输入图像的区域之间的关系，而解码器读取每个编码层的输出以逐字生成描述。</p>
<p>结构图为：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/1f726498ee2654388e56706d7a444e65.png" alt></p>
<p>注意力操作为：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/ef1e77cb36ae33b1b8f74fe8ea6c37ab.png" alt></p>
<h4 id="2-memory-augmented-encoder"><a class="markdownIt-Anchor" href="#2-memory-augmented-encoder"></a> 2、Memory-Augmented Encoder</h4>
<p>self-attention operation：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/9044fde7e7b4fc15877f955a7d4cc816.png" alt></p>
<p>其中X表示提取出的一组图像区域特征。</p>
<p>问题：self-attention只关注输入集合两两之间的相似性，所以不能对图像区域之间的先验知识进行建模，比如给定“man”和“basketball”的区域编码特征，如果没有先验知识的话很难推断出“player”或者“game”的概念，同样，给定“eggs”和“toasts”的区域特征，可以很容易地利用关系的先验知识推断出图片是在描述“breakfast”的知识。</p>
<p>所以作者提出了<strong>Memory-Augmented Attention</strong>，对self-attention的key和value进行扩展，额外的“插槽”可以编码先验信息：</p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/8b89eac48a8db626a3ffd58a336c2f20.png" alt></p>
<p><strong>Encoding layer:</strong></p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/8b6a46a06722d0f46e2f4f8f4955e7a7.png" alt></p>
<p><strong>Full encoder:</strong></p>
<p>将多个Encoding layer叠加起来，从多层次提取图像区域之间的关系。</p>
<h4 id="3-meshed-decoder"><a class="markdownIt-Anchor" href="#3-meshed-decoder"></a> 3、Meshed Decoder</h4>
<p>为了在句子的生成过程中利用所有的编码层输出的多层次表示，编码层和解码层之间采用网状连接。</p>
<p><strong>Meshed Cross-Attention</strong></p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/f60d0f9a2b66b297c80177a1a8f2e69e.png" alt></p>
<p>α中的权重既调节每个编码层的输出特征集合之间的贡献，也调节不同层之间的相对重要性。</p>
<p><strong>Architecture of decoding layers</strong></p>
<p><img src="/2021/02/08/Transformer-Related-Image-Captioning-2/786c6639e19249a1963e606fcc4d355f.png" alt></p>
<p>因为只依赖于前面已经生成的单词集合，所以采用了masked self-attention operation。</p>

    </div>

    
    
    
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/Image-Caption/" rel="tag"><i class="fa fa-tag"></i> Image Caption</a>
            
              <a href="/tags/Attention-Mechanism/" rel="tag"><i class="fa fa-tag"></i> Attention Mechanism</a>
            
              <a href="/tags/Transformer/" rel="tag"><i class="fa fa-tag"></i> Transformer</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2021/02/01/Attention-Related-Image-Captioning-4/" rel="next" title="Attention-Related Image Captioning (4)">
                  <i class="fa fa-chevron-left"></i> Attention-Related Image Captioning (4)
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          文章目录
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc">
            <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一-normalized-and-geometry-aware-self-attention-network-for-image-captioning-cvpr2020"><span class="nav-text"> 一、Normalized and Geometry-Aware Self-Attention Network for Image Captioning, CVPR2020</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-解决问题"><span class="nav-text"> 1、解决问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-准备工作"><span class="nav-text"> 2、准备工作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-模型"><span class="nav-text"> 3、模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1normalized-sa-nsa"><span class="nav-text"> 1）Normalized SA (NSA)：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2geometry-aware-sa-gsa"><span class="nav-text"> 2）Geometry-Aware SA (GSA)：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3ng-san"><span class="nav-text"> 3）NG-SAN</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二-meshed-memory-transformer-for-image-captioning-cvpr2020"><span class="nav-text"> 二、Meshed-Memory Transformer for Image Captioning, CVPR2020</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-meshed-memory-transformer"><span class="nav-text"> 1、Meshed-Memory Transformer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-memory-augmented-encoder"><span class="nav-text"> 2、Memory-Augmented Encoder</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-meshed-decoder"><span class="nav-text"> 3、Meshed Decoder</span></a></li></ol></li></ol></li></ol></div>
          </div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.jpg"
      alt="Ezeli">
  <p class="site-author-name" itemprop="name">Ezeli</p>
  <div class="site-description motion-element" itemprop="description">个人笔记：用于总结和回顾！</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">56</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/ezeli" title="GitHub &rarr; https://github.com/ezeli" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:327578505@qq.com" title="E-Mail &rarr; mailto:327578505@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      我的项目
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://github.com/ezeli/Transformer_model" title="https://github.com/ezeli/Transformer_model" rel="noopener" target="_blank">Transformer 模型</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="https://github.com/ezeli/BUTD_model" title="https://github.com/ezeli/BUTD_model" rel="noopener" target="_blank">Attention 模型</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="https://github.com/ezeli/NIC_model" title="https://github.com/ezeli/NIC_model" rel="noopener" target="_blank">NIC 模型</a>
        </li>
      
    </ul>
  </div>

        </div>
      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ezeli</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        












        
      </div>
    </footer>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a class="book-mark-link book-mark-link-fixed" href="#"></a>

  <a href="https://github.com/ezeli" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="//cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-nest@1/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script><script src="/js/bookmark.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>

    
  

  <script>
    ;((d, w) => {
      loadThree = () => {
        let s = d.createElement('script');
        s.src = '//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js';
        d.body.appendChild(s);
      }
      let styles = ['', '//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/canvas_lines.min.js', ''];
      loadStyle = () => {
        styles.forEach(x => {
          if (x !== '') {
            let s = d.createElement('script');
            s.src = x;
            d.body.appendChild(s);
          }
        })
      }
      w.addEventListener('DOMContentLoaded', loadThree);
      w.addEventListener('load', loadStyle);
    })(document, window);
  </script>


  








  <script src="/js/local-search.js?v=7.3.0"></script>








<script>
if (document.querySelectorAll('div.pdf').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/pdfobject@2/pdfobject.min.js', () => {
    document.querySelectorAll('div.pdf').forEach(element => {
      PDFObject.embed(element.getAttribute('target'), element, {
        pdfOpenParams: {
          navpanes: 0,
          toolbar: 0,
          statusbar: 0,
          pagemode: 'thumbs',
          view: 'FitH'
        },
        PDFJS_URL: '/lib/pdf/web/viewer.html',
        height: element.getAttribute('height') || '500px'
      });
    });
  }, window.PDFObject);
}
</script>






  

  
    
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">
  <script src="//cdn.jsdelivr.net/npm/katex@0/dist/contrib/copy-tex.min.js"></script>
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/contrib/copy-tex.min.css">

    
  

  

  


  
  <script src="/js/post-details.js?v=7.3.0"></script>


</body>
</html>
